# Configuration reference: http://docs.postiz.com/configuration/reference

# === Required Settings
DATABASE_URL="postgresql://postiz-user:postiz-password@localhost:5432/postiz-db-local"
REDIS_URL="redis://localhost:6379"
JWT_SECRET="random string for your JWT secret, make it long"

# === This needs to be exactly the URL you're accessing Postiz on
FRONTEND_URL="http://localhost:4200"
NEXT_PUBLIC_BACKEND_URL="http://localhost:3000"
BACKEND_INTERNAL_URL="http://localhost:3000"

## Remember to set your public internet IP address in the allow-list for the API token.
##
## Cloudflare is currently required to save things like social media avatars for accounts.
CLOUDFLARE_ACCOUNT_ID="your-account-id"
CLOUDFLARE_ACCESS_KEY="your-access-key"
CLOUDFLARE_SECRET_ACCESS_KEY="your-secret-access-key"
CLOUDFLARE_BUCKETNAME="your-bucket-name"
CLOUDFLARE_BUCKET_URL="https://your-bucket-url.r2.cloudflarestorage.com/"
CLOUDFLARE_REGION="auto"

# === Common optional Settings

## This is a dummy key, you must create your own from Resend.
## If this variable exists, user activation is required.
## If it is commented out, users are activated automatically.
#RESEND_API_KEY="RzeTwHijvxvPUerScFcenUZUALuQJzSaGSMJ"
#EMAIL_FROM_ADDRESS=""
#EMAIL_FROM_NAME=""
#DISABLE_REGISTRATION=false

# ===================================================================
# STORAGE CONFIGURATION
# ===================================================================
# Where will social media icons and uploaded files be saved.
# Supported providers: local, cloudflare, s3-compatible, ftp, sftp
STORAGE_PROVIDER="local"

# === LOCAL STORAGE ===
# Your upload directory path if you host your files locally
#UPLOAD_DIRECTORY="/path/to/upload/directory"
#NEXT_PUBLIC_UPLOAD_STATIC_DIRECTORY="/uploads"

# === CLOUDFLARE R2 STORAGE ===
# Cloudflare R2 is S3-compatible and used for the existing cloudflare provider
#CLOUDFLARE_ACCOUNT_ID="your-account-id"
#CLOUDFLARE_ACCESS_KEY="your-access-key"
#CLOUDFLARE_SECRET_ACCESS_KEY="your-secret-access-key"
#CLOUDFLARE_BUCKETNAME="your-bucket-name"
#CLOUDFLARE_BUCKET_URL="https://your-bucket-url.r2.cloudflarestorage.com/"
#CLOUDFLARE_REGION="auto"

# === S3-COMPATIBLE STORAGE ===
# Works with AWS S3, MinIO, DigitalOcean Spaces, Backblaze B2, Wasabi, and more
#S3_COMPATIBLE_ACCESS_KEY="your-access-key"
#S3_COMPATIBLE_SECRET_KEY="your-secret-key"
#S3_COMPATIBLE_REGION="us-east-1"
#S3_COMPATIBLE_BUCKET="your-bucket-name"

# Optional: Custom S3 endpoint (for non-AWS providers)
#S3_COMPATIBLE_ENDPOINT="https://s3.us-east-1.amazonaws.com"
# Examples:
# MinIO: "http://localhost:9000" or "https://minio.example.com"
# DigitalOcean: "https://nyc3.digitaloceanspaces.com"
# Backblaze B2: "https://s3.us-west-001.backblazeb2.com"
# Wasabi: "https://s3.us-east-1.wasabisys.com"

# Optional: Public URL where files will be accessible (overrides auto-generated URL)
#S3_COMPATIBLE_PUBLIC_URL="https://cdn.example.com"
# Examples:
# AWS S3: "https://my-bucket.s3.us-east-1.amazonaws.com"
# MinIO: "https://cdn.example.com" (with reverse proxy)
# DigitalOcean: "https://my-space.nyc3.cdn.digitaloceanspaces.com"

# Optional: Use path-style URLs (required for MinIO, optional for others)
#S3_COMPATIBLE_PATH_STYLE=false

# Optional: Generate signed URLs for private buckets
#S3_COMPATIBLE_SIGNED_URLS=false
#S3_COMPATIBLE_SIGNED_URL_EXPIRY=3600

# === FTP STORAGE ===
# Upload files via FTP protocol to any FTP server
#FTP_HOST="ftp.example.com"
#FTP_PORT=21
#FTP_USER="ftpuser"
#FTP_PASSWORD="ftppassword"
#FTP_REMOTE_PATH="/public_html/uploads"
#FTP_PUBLIC_URL="https://example.com/uploads"

# Optional: Use FTPS (FTP over SSL/TLS)
#FTP_SECURE=false

# Optional: Use passive FTP mode (recommended for most setups)
#FTP_PASSIVE_MODE=true

# === SFTP STORAGE ===
# Upload files via SFTP (SSH File Transfer Protocol)
#SFTP_HOST="sftp.example.com"
#SFTP_PORT=22
#SFTP_USER="sftpuser"
#SFTP_REMOTE_PATH="/var/www/uploads"
#SFTP_PUBLIC_URL="https://example.com/uploads"

# Authentication: Use either password OR SSH key (not both)
#SFTP_PASSWORD="sftppassword"
#SFTP_PRIVATE_KEY_PATH="/path/to/private/key"

# Social Media API Settings
X_API_KEY=""
X_API_SECRET=""
LINKEDIN_CLIENT_ID=""
LINKEDIN_CLIENT_SECRET=""
REDDIT_CLIENT_ID=""
REDDIT_CLIENT_SECRET=""
GITHUB_CLIENT_ID=""
GITHUB_CLIENT_SECRET=""
BEEHIIVE_API_KEY=""
BEEHIIVE_PUBLICATION_ID=""
LISTMONK_DOMAIN=""
LISTMONK_USER=""
LISTMONK_API_KEY=""
LISTMONK_LIST_ID=""
THREADS_APP_ID=""
THREADS_APP_SECRET=""
FACEBOOK_APP_ID=""
FACEBOOK_APP_SECRET=""
YOUTUBE_CLIENT_ID=""
YOUTUBE_CLIENT_SECRET=""
TIKTOK_CLIENT_ID=""
TIKTOK_CLIENT_SECRET=""
PINTEREST_CLIENT_ID=""
PINTEREST_CLIENT_SECRET=""
DRIBBBLE_CLIENT_ID=""
DRIBBBLE_CLIENT_SECRET=""
DISCORD_CLIENT_ID=""
DISCORD_CLIENT_SECRET=""
DISCORD_BOT_TOKEN_ID=""
SLACK_ID=""
SLACK_SECRET=""
SLACK_SIGNING_SECRET=""
MASTODON_URL="https://mastodon.social"
MASTODON_CLIENT_ID=""
MASTODON_CLIENT_SECRET=""

# Misc Settings
OPENAI_API_KEY=""
NEXT_PUBLIC_DISCORD_SUPPORT=""
NEXT_PUBLIC_POLOTNO=""
# NOT_SECURED=false

# ========================================
# AI Provider Configuration
# ========================================
# Configure multiple AI providers for load balancing, failover, and cost optimization
# Pattern: AI_PROVIDERNAME_* (only providers with AI_*_KEY set will be loaded)
#
# Quick Start: Just set AI_OPENAI_KEY or AI_OPENROUTER_KEY to get started
# Documentation: See dev-docs/ai-provider-system.md for full guide

# OpenAI Provider (recommended for image generation)
AI_OPENAI_URL=""                    # Optional, defaults to https://api.openai.com/v1
AI_OPENAI_KEY=""                    # Your OpenAI API key (sk-proj-...)
AI_OPENAI_SMART="gpt-4.1"           # Model for complex tasks (image prompts, voice conversion, slides)
AI_OPENAI_FAST="gpt-4o-mini"        # Model for simple tasks (post generation, text extraction)
AI_OPENAI_ENABLED="true"            # Enable/disable this provider
AI_OPENAI_WEIGHT="1"                # Weight for weighted rotation (optional)

# OpenRouter Provider (recommended for Claude/Gemini access)
AI_OPENROUTER_URL="https://openrouter.ai/api/v1"
AI_OPENROUTER_KEY=""                # Your OpenRouter API key (sk-or-v1-...)
AI_OPENROUTER_SMART="anthropic/claude-3.5-sonnet"
AI_OPENROUTER_FAST="anthropic/claude-3-haiku"
AI_OPENROUTER_ENABLED="true"
AI_OPENROUTER_WEIGHT="1"

# Azure OpenAI Provider (enterprise)
AI_AZURE_URL=""                     # Your Azure OpenAI endpoint (https://yourname.openai.azure.com)
AI_AZURE_KEY=""                     # Your Azure OpenAI API key
AI_AZURE_SMART="gpt-4"              # Azure model deployment name
AI_AZURE_FAST="gpt-35-turbo"        # Azure model deployment name
AI_AZURE_ENABLED="false"
AI_AZURE_WEIGHT="1"

# Groq Provider (ultra-fast inference)
AI_GROQ_URL="https://api.groq.com/openai/v1"
AI_GROQ_KEY=""                      # Your Groq API key (gsk-...)
AI_GROQ_SMART="mixtral-8x7b-32768"
AI_GROQ_FAST="llama3-8b-8192"
AI_GROQ_ENABLED="false"
AI_GROQ_WEIGHT="1"

# Together AI Provider (open source models)
# AI_TOGETHER_URL="https://api.together.xyz/v1"
# AI_TOGETHER_KEY=""                # Your Together AI API key
# AI_TOGETHER_SMART="mistralai/Mixtral-8x22B-Instruct-v0.1"
# AI_TOGETHER_FAST="meta-llama/Llama-3-8b-chat-hf"
# AI_TOGETHER_ENABLED="false"

# Custom/Self-hosted Provider (your own OpenAI-compatible API)
# AI_CUSTOM_URL="https://your-api.com/v1"
# AI_CUSTOM_KEY="your-custom-key"
# AI_CUSTOM_SMART="your-large-model"
# AI_CUSTOM_FAST="your-small-model"
# AI_CUSTOM_ENABLED="false"

# Global AI Settings
AI_ROTATION="round-robin"           # Strategy: round-robin, random, weighted, failover
AI_RETRY_FAILED="true"              # Retry with next provider on failure
AI_MAX_RETRIES="3"                  # Maximum retries across all providers

# ========================================
# Per-Task AI Model Assignment
# ========================================
# Assign different AI providers/models to specific tasks
# This allows using different providers for image generation, text generation, video, and the agent
# Pattern: AI_TASKTYPE_PROVIDER and AI_TASKTYPE_MODEL

# IMAGE GENERATION CONFIGURATION
# Use OpenAI DALL-E, Gemini, or other OpenAI-compatible image models
AI_IMAGE_PROVIDER="openai"                    # Provider: openai, anthropic, openai-compatible, gemini, custom
AI_IMAGE_MODEL="dall-e-3"                     # OpenAI: dall-e-3 (recommended), dall-e-2
AI_IMAGE_FALLBACK_PROVIDER="openai"           # Fallback provider if primary fails
AI_IMAGE_FALLBACK_MODEL="dall-e-3"

# TEXT GENERATION CONFIGURATION (for generating posts, slides, etc.)
# Use GPT-4, Claude, or other LLM providers
AI_TEXT_PROVIDER="openai"                     # Provider: openai, anthropic, openai-compatible, gemini, custom
AI_TEXT_MODEL="gpt-4.1"                       # OpenAI: gpt-4.1, gpt-4o, gpt-4o-mini
                                              # Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20250219
AI_TEXT_FALLBACK_PROVIDER="openai"            # Fallback provider if primary fails
AI_TEXT_FALLBACK_MODEL="gpt-4o-mini"

# VIDEO GENERATION (Image-to-Video slides with AI narration)
# For generating videos from images and text
AI_VIDEO_SLIDES_PROVIDER="openai"             # Provider: openai, anthropic, openai-compatible, gemini, custom
AI_VIDEO_SLIDES_MODEL="gpt-4.1"               # Model for slide generation (text-based task)
AI_VIDEO_SLIDES_FALLBACK_PROVIDER="openai"
AI_VIDEO_SLIDES_FALLBACK_MODEL="gpt-4o-mini"

# AGENT CONFIGURATION (Mastra AI Agent)
# The AI provider used by the social media management agent
AI_AGENT_PROVIDER="openai"                    # Provider: openai, anthropic, openai-compatible, gemini, custom
AI_AGENT_MODEL="gpt-4.1"                      # Should be a capable model for agent reasoning
AI_AGENT_FALLBACK_PROVIDER="openai"
AI_AGENT_FALLBACK_MODEL="gpt-4o-mini"

# ========================================
# OpenAI-Compatible Providers (Custom APIs)
# ========================================
# Use these for custom OpenAI-compatible endpoints, Gemini via OpenAI format, Ollama, etc.

# GEMINI via OpenAI-Compatible API
#GEMINI_API_KEY=""                            # Your Gemini API key
#GEMINI_BASE_URL="https://generativelanguage.googleapis.com/openai/"

# OLLAMA (Local LLM Inference)
# Run Ollama locally: ollama run mistral
#OLLAMA_BASE_URL="http://localhost:11434/v1"  # Change if Ollama runs on different port

# TOGETHER AI (Open Source Models)
#TOGETHER_API_KEY=""                          # Your Together AI API key
#TOGETHER_BASE_URL="https://api.together.xyz/v1"

# CUSTOM OpenAI-Compatible Provider
#OPENAI_COMPATIBLE_API_KEY=""                 # API key for your custom provider
#OPENAI_COMPATIBLE_BASE_URL=""                # Base URL of your custom API

# ANTHROPIC (Claude Models)
#ANTHROPIC_API_KEY=""                         # Your Anthropic API key

# ========================================
# Legacy Configuration (backward compatibility)
# ========================================
# These settings are still supported but will be automatically converted
# to the new AI provider system if no AI_*_KEY variables are set
# OPENAI_API_KEY=""                 # Legacy: Use AI_OPENAI_KEY instead
# OPENAI_BASE_URL=""                # Legacy: Use AI_OPENAI_URL instead
# SMART_LLM=""                      # Legacy: Use AI_*_SMART instead
# FAST_LLM=""                       # Legacy: Use AI_*_FAST instead
API_LIMIT=30 # The limit of the public API hour limit

# Payment settings
FEE_AMOUNT=0.05
STRIPE_PUBLISHABLE_KEY=""
STRIPE_SECRET_KEY=""
STRIPE_SIGNING_KEY=""
STRIPE_SIGNING_KEY_CONNECT=""

# Developer Settings
NX_ADD_PLUGINS=false
IS_GENERAL="true" # required for now
NEXT_PUBLIC_POSTIZ_OAUTH_DISPLAY_NAME="Authentik"
NEXT_PUBLIC_POSTIZ_OAUTH_LOGO_URL="https://raw.githubusercontent.com/walkxcode/dashboard-icons/master/png/authentik.png"
POSTIZ_GENERIC_OAUTH="false"
POSTIZ_OAUTH_URL="https://auth.example.com"
POSTIZ_OAUTH_AUTH_URL="https://auth.example.com/application/o/authorize"
POSTIZ_OAUTH_TOKEN_URL="https://auth.example.com/application/o/token"
POSTIZ_OAUTH_USERINFO_URL="https://authentik.example.com/application/o/userinfo"
POSTIZ_OAUTH_CLIENT_ID=""
POSTIZ_OAUTH_CLIENT_SECRET=""
# POSTIZ_OAUTH_SCOPE="openid profile email" # default values

# Short Link Service Settings
# DUB_TOKEN="" # Your self-hosted Dub API token
# DUB_API_ENDPOINT="https://api.dub.co" # Your self-hosted Dub API endpoint
# DUB_SHORT_LINK_DOMAIN="dub.sh" # Your self-hosted Dub domain

# SHORT_IO_SECRET_KEY="" # Your Short.io API secret key

# KUTT_API_KEY="" # Your Kutt.it API key
# KUTT_API_ENDPOINT="https://kutt.it/api/v2" # Your self-hosted Kutt API endpoint
# KUTT_SHORT_LINK_DOMAIN="kutt.it" # Your self-hosted Kutt domain

# LINK_DRIP_API_KEY="" # Your LinkDrip API key
# LINK_DRIP_API_ENDPOINT="https://api.linkdrip.com/v1/" # Your self-hosted LinkDrip API endpoint
# LINK_DRIP_SHORT_LINK_DOMAIN="dripl.ink" # Your self-hosted LinkDrip domain